Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
3000,1.4186673,0.00029955019,0.0056510563,0.11824999791570008,0.11824999735690653,999.5,0.018505935,0.020540163
6000,1.4176292,0.00029865018,-0.00637047,0.095333331823349,0.09533333120246729,1000.0,0.0036863978,0.016481256
9000,1.4182546,0.00029775014,-0.0005189916,0.09433333026245236,0.09433333122481903,1000.0,0.0014343648,0.016338417
12000,1.4182057,0.00029685016,1.0362011e-05,0.08183333116273085,0.0818333315042158,1000.0,0.00085937534,0.020980459
15000,1.417684,0.0002959502,0.006791949,0.13116666451096534,0.13116666373486321,1000.0,0.0008167645,0.015121497
18000,1.4167145,0.00029505018,0.012848903,0.1553333287127316,0.15533332986136278,1000.0,0.00070027105,0.019253409
